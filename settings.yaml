# ===============================================================================
#
# Purpose: General settings for a Dandere2x session
#
# ===============================================================================
#
# This program is free software: you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
# You should have received a copy of the GNU General Public License along with
# this program. If not, see <http://www.gnu.org/licenses/>.
#
# ===============================================================================



# The options are written as:
#
# [Comments or quick guide if needed]
# [option]: [value]  # Info or possible values - [recomended / default value]



##############################################################################################
##                                                                                          ##
## IF UNSURE DO NOT CHANGE THE DEFAULTS SETTINGS, SPECIALLY BLEED, TILE SIZE AND BLOCK SIZE ##
##                                                                                          ##
##############################################################################################



basic:
  # I highly recommend upscaling this "yn_moving_480.mkv" sample for testing if everything is working before a big session
  input_file: samples/yn_moving480.mkv

  # "auto" adds a "2x_" prefix to the filename and sets the output to the same directory
  output_file: auto  # [auto]

  # auto sets the session name to the input video filename
  session_name: auto  # [auto]

  
block_matching:
  #    Maybe the trickiest part.. IT ALL DEPENDS ON THE SOURCE FILE!!
  #
  #  (numbers for a 720p source video) 
  # Generally speaking, lower block sizes (< 12) yields longer upscale and might be less precise..
  # Too big (> 40~) you'll be wasting too much Waifu2x upscales on not necessary parts
  #
  # A number between 20 should be enough for every video and for lower res (480p), 15 might be doable
  # 
  # [TODO] Make sure the remainder of both width and height divided by the block size aren't too small (1 - 5~)
  # This is because for example the source is a 100x100 video and the block size is 33, there will be one 1x1 block
  # three 33x1 and three 1x33 blocks on the bottom / right edges and corner of the video, need to decide how I'll handle this
  # 1080p, 720p, 480p are fine with block size 20
  block_size: 20

  block_size_auto_adapt: null # NOT IMPLEMENTED YET, FIXES STUPID CORNER / EDGE BLOCK SIZES

  # These are how agressive the block matching is, lower values will catch more blocks;
  # dark and bright are determined by the mean pixel value of every channel on a frame
  # and then apply a linear function to get the final threshold, 0=dark, 255=bright
  # This seems to make block matching better as darker frames not a lot of colors are moving
  #
  # Suggested values:
  #   
  #   [High quality] Almost none bad blocks but quite a few wrong matched and upscaled ones:
  #      Good for very subtle moving / gradient changes in the source file
  #      - dark_threshold: 0.0035
  #      - bright_threshold: 0.0045
  #
  #   [Medium quality] Minor bad blocks on either anime / IRL and few wrong matched and upscaled:
  #      Good for a general standpoint, though with slow transitions the blocks may be a bit noticeable
  #      - dark_threshold: 0.01
  #      - bright_threshold: 0.015
  #
  #   [Low quality] Treshold pretty high, only a small "big" change in the blocks will be processed
  #      Good for a slideshow / very static anime or potentially bad encoded videos?
  #      - dark_threshold: 0.025
  #      - bright_threshold: 0.027
  #
  dark_threshold: 0.01  # [0.01]
  bright_threshold: 0.015  # [0.015]

  # A "over-crop" of the blocks in the original source to reduce blockiness as Waifu2x bleeds a bit on the residuals
  #  A quick guide on the values:
  #
  #   0: Fastest, visible blocks everywhere
  #
  #   1: Better for faster and high quality upscales, minor visible blocks
  #
  #   2: Best quality at cost of larger upscale times, almost no visible blockiness
  #
  #   3: Not much difference from 2, only if the upscaler is bleeding A LOT, values should not be higher than this
  bleed: 1  # [1]


waifu2x:
  #   Waifu2x types: see linked repos on README.md or main project page for more info about them
  #
  # fake:  WINDOWS + LINUX
  #     For testing the raw speed of Dandere2x Python implementation, standard upscaling
  # 
  # vulkan:  WINDOWS + LINUX
  #     Uses nihui's waifu2x-ncnn-vulkan implementation
  #     We prefer this as it's the less troublesome and faster one, though you gotta have a Vulkan capable GPU
  #
  # cpp:  WINDOWS + LINUX
  #     Uses DeadSix27's waifu2x-converter-cpp implementation
  #     The most compatible one (probably)
  #
  # caffe:  WINDOWS
  #     Not implemented yet
  #
  waifu2x_type: vulkan  # fake, cpp, vulkan - [vulkan]

  # How much denoise the Waifu2x model will apply, generally speaking lower is sharper but less smooth
  # 
  # 1 is good for IRL
  # 2 isn't as agressive
  # 3 yields very plastic images and distorts a bit the lines, good for anime
  denoise_level: 2  # [2]

  # The tile size affects total GPU VRAM usage, smaller values increases upscale time.
  # The ideal spot is somewhere in the 200 - 400 range, 200 uses about 1 GB VRAM
  tile_size: 200  # [200]

  # Waifu2x Vulkan models:
  #   - models-upconv_7_anime_style_art_rgb
  #   - models-upconv_7_photo
  #   - models-cunet
  #
  # Only Vulkan uses this for now
  waifu2x_model: models-cunet  # [models-cunet]

  # Linux only!!
  # Use RADV_PERFTEST=aco when calling Waifu2x subprocess, I get 50% faster results
  # Only for AMD GPUs running a compatible Mesa adapter, should not interfere if set to true on NVIDIA GPUs as they don't use Mesa
  linux_enable_mesa_aco_waifu2x_vulkan: true  # [true]


# Stats are a bit primitive as for now, though they work on a basic level
stats:
  # Show stats about completion and ETAs
  # Better be used with loglevel=1 on CLI interface
  show_stats: true  # [true]

  # Tell the average processing time of these last N frames
  average_last_N_frames: 120  # [120]


danger_zone:
  # Forces resume=False if true (deletes session folder before upscaling)
  force: false  # [false]

  # Without mindisk, C++ will do everything it needs to do ASAP:
  # Generates all residuals, technically should be the fastest.
  # Waifu2x upscales in random order so may take a while to get the first images going
  # Mindisk on, C++ waits until a certain residual doesn't exist on the disk
  mindisk: true  # [true]


video:
  # How to get the video info like resolution, frame count and frame rate
  # Options are "ffmpeg" or "mediainfo"
  # ffmpeg is the safest (?), uses ffmpeg and ffprobe binaries
  get_video_info_method: ffmpeg  # [ffmpeg]

  # mediainfo before overrides these next options
  get_frame_count_method: null_copy  # Only option available right now
  get_frame_rate_method: ffprobe  # Only option available right now
  get_resolution_method: ffprobe  # Only option available right now
  

ffmpeg:
  # Here's some good filters you might try out

  # 1. Old deblocking, more "general"
  #     pp=hb/vb/dr/fq|32, deband=range=22:blur=false

  # 2. Nice deblocking on anime
  #     deband=range=8:blur=false, pp7=qp=2:mode=medium  

  # 3. Better for IRL videos:
  #     deband=range=8:blur=false, pp7=qp=2:mode=medium, unsharp
  #
  deblock_filter: deband=range=8:blur=false, pp7=qp=2:mode=medium  # [number 2.] 
  encode_codec: libx264  # [libx264]

  # Settings for the x264 encoder on FFmpeg's libx264
  x264:
    # See https://trac.ffmpeg.org/wiki/Encode/H.264 for a guide
    preset: slow
    tune: animation
    crf: 18


# AVOID FOR NOW
# Apply vapoursynth scripts before / after the upscale
# Not tested on Windows, Linux seems to be working if you have the required stuff
# And you should be a power user if you're using this anyway, just have "vspipe" and "x264" in path and the script modules you're gonna use
# See demo scripts on how to set the input video
vapoursynth:
  enabled: false
  # To disable these filters set them to "null" or "none"
  pre: transpose  # name of filter within ./vpys/$NAME$, applied BEFORE ffmpeg noise and upscaled
  pos: transpose  # name of filter within ./vpys/$NAME$, applied AFTER everything


developer:

  # Write log to disk? 
  write_log: true  # [true]

  # Verbose of Dandere2x, ranges from 0 to 10
  #   Note: loglevel 0 doesn't mean no output, just not the essential ones and the setting up session logs
  #   10 is ULTRA SLOW and shows all the vectors we're substituting, avoid if only not for the fun or hard hard hard debugging
  loglevel: 1  # [1]

  # How much Current - N frames behind to delete the residuals or upscaled residuals
  safety_ruthless_residual_eliminator_range: 3  # [3]

  # Time Python waits for a file to exist
  wait_time_exists: 0.05  # [0.05]

  # Time Waifu2x sleeps after upscaling everything or nothing from residuals input folder
  waifu2x_wait_for_residuals: 0.1  # [0.1]


specific:
  colors_output: true  # Doesn't work yet


debug:
  # Only do the block matching and save the block matched frames into a debug video as well as show stats
  # just for fun and some R&D with numbers :)
  write_only_debug_video: false  # [false]
  enable_waifu2x: true  # [true]
